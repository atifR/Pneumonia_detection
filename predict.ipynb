{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook to calssify pneumonia\n",
    "\n",
    "The data is taken from <br>\n",
    "https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms.v2 as v2\n",
    "import math\n",
    "import time \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Settings ... \n",
      " dataset path \t\t Dataset \n",
      " batch_size \t\t 32 \n",
      " device \t\t cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_folder  = \"Dataset\"\n",
    "train_folder = \"train\"\n",
    "valid_folder = \"val\"\n",
    "test_folder = \"test\"\n",
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "print (f\"Settings ... \\n dataset path \\t\\t {dataset_folder} \\n batch_size \\t\\t {batch_size}\" +\n",
    "       f\" \\n device \\t\\t {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the classes in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class_labels = [name for name in os.listdir(f\"{dataset_folder}/{train_folder}\") if not name.startswith(\".DS_Store\")]\n",
    "print(class_labels)\n",
    "num_classes = len(class_labels)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from the image folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transformations = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomResizedCrop(size=(256, 256), antialias=True),\n",
    "    v2.RandomRotation(degrees = (0, 170)),\n",
    "    v2.ToDtype(dtype = torch.float32, scale = True),\n",
    "    v2.Resize(size = (256, 256), antialias = True),\n",
    "    v2.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(f\"{dataset_folder}/{train_folder}\", transform = transformations)\n",
    "valid_dataset = ImageFolder(f\"{dataset_folder}/{valid_folder}\", transform = transformations)\n",
    "test_dataset = ImageFolder(f\"{dataset_folder}/{test_folder}\", transform = transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probe stats from the Image folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "print (f\"classes {train_dataset.classes}\")\n",
    "d = train_dataset.class_to_idx\n",
    "\n",
    "num_classes =2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of training dataset 5216\n",
      "Lenght of validation dataset 16\n",
      "Lenght of test dataset 624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset,shuffle=True,batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=batch_size)\n",
    "\n",
    "print(f\"Lenght of training dataset {len(train_dataloader.dataset)}\")\n",
    "print(f\"Lenght of validation dataset {len(valid_dataloader.dataset)}\")\n",
    "print(f\"Lenght of test dataset {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in res_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "res_net.fc  = torch.nn.Sequential(\n",
    "    nn.Linear(2048,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(\n",
    "        in_features=128,\n",
    "        out_features=num_classes\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANy other model(s) to evalaute can go here ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = res_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(res_net.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_name,criterion,optimier, data_loader,device, num_epochs=0):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        #loss_batches = 0\n",
    "        loss_epoch=0;\n",
    "        corrects_batches = 0\n",
    "        count = 0\n",
    "        start = time.time()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        data_loading_begin = time.time()\n",
    "        data_loading_time = 0\n",
    "        data_processing_time = 0 \n",
    "        for x,y in data_loader:\n",
    "            \n",
    "            x,y = x.to(device), y.to(device)\n",
    "            data_loading_time += (time.time()-data_loading_begin)\n",
    "            processing_time_begin = time.time()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs,y)\n",
    "            optimier.zero_grad()\n",
    "            loss.backward()\n",
    "            optimier.step()\n",
    "            data_processing_time += (time.time()-processing_time_begin)\n",
    "            _,preds = torch.max(outputs,1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += preds.size(0)\n",
    "            loss_epoch += loss.item()\n",
    "            count += 1\n",
    "            data_loading_begin = time.time()\n",
    "        #epoch_loss = loss_batches / len(data_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"\\n epoch {epoch} Loss : {(loss_epoch/count):.4f} Accuracy {epoch_acc:.2f}, time : {time.time()-start} secs\")\n",
    "        print(f\"data loading time {data_loading_time} secs, data processing time {data_processing_time} secs\")\n",
    "        if (epoch % 3 == 0 ):\n",
    "          torch.save(model.state_dict(),f\"{model_name}_{epoch:02d}_{epoch_acc:.2f}.h5\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch 0 Loss : 0.3612 Accuracy 0.84, time : 516.2087528705597 secs\n",
      "data loading time 467.64172530174255 secs, data processing time 39.198058128356934 secs\n",
      "\n",
      " epoch 1 Loss : 0.3355 Accuracy 0.85, time : 226.7957444190979 secs\n",
      "data loading time 215.22204685211182 secs, data processing time 3.7457752227783203 secs\n",
      "\n",
      " epoch 2 Loss : 0.3128 Accuracy 0.86, time : 223.42679500579834 secs\n",
      "data loading time 211.8066189289093 secs, data processing time 3.8180460929870605 secs\n",
      "\n",
      " epoch 3 Loss : 0.2983 Accuracy 0.87, time : 251.41879224777222 secs\n",
      "data loading time 239.6731083393097 secs, data processing time 3.717101812362671 secs\n",
      "\n",
      " epoch 4 Loss : 0.3029 Accuracy 0.87, time : 357.66844034194946 secs\n",
      "data loading time 345.3748390674591 secs, data processing time 3.828052043914795 secs\n",
      "\n",
      " epoch 5 Loss : 0.2890 Accuracy 0.87, time : 283.5943007469177 secs\n",
      "data loading time 272.01806807518005 secs, data processing time 3.81483793258667 secs\n",
      "\n",
      " epoch 6 Loss : 0.2902 Accuracy 0.87, time : 240.40447068214417 secs\n",
      "data loading time 229.07391548156738 secs, data processing time 3.856816053390503 secs\n",
      "\n",
      " epoch 7 Loss : 0.2909 Accuracy 0.87, time : 223.04251050949097 secs\n",
      "data loading time 211.79501056671143 secs, data processing time 3.8147671222686768 secs\n",
      "\n",
      " epoch 8 Loss : 0.2769 Accuracy 0.88, time : 219.12473440170288 secs\n",
      "data loading time 207.79328536987305 secs, data processing time 3.706812858581543 secs\n",
      "\n",
      " epoch 9 Loss : 0.2756 Accuracy 0.88, time : 233.73629117012024 secs\n",
      "data loading time 222.5047583580017 secs, data processing time 3.7798104286193848 secs\n",
      "\n",
      " epoch 10 Loss : 0.2686 Accuracy 0.89, time : 227.3571219444275 secs\n",
      "data loading time 216.0215198993683 secs, data processing time 3.802868366241455 secs\n",
      "\n",
      " epoch 11 Loss : 0.2665 Accuracy 0.89, time : 233.26432728767395 secs\n",
      "data loading time 221.93557143211365 secs, data processing time 3.7609457969665527 secs\n",
      "\n",
      " epoch 12 Loss : 0.2748 Accuracy 0.88, time : 229.78402662277222 secs\n",
      "data loading time 218.40830326080322 secs, data processing time 3.788925886154175 secs\n",
      "\n",
      " epoch 13 Loss : 0.2676 Accuracy 0.88, time : 215.60414052009583 secs\n",
      "data loading time 204.19842314720154 secs, data processing time 3.6530213356018066 secs\n",
      "\n",
      " epoch 14 Loss : 0.2856 Accuracy 0.88, time : 240.33347630500793 secs\n",
      "data loading time 229.06267642974854 secs, data processing time 3.5344958305358887 secs\n",
      "\n",
      " epoch 15 Loss : 0.2576 Accuracy 0.89, time : 221.63825631141663 secs\n",
      "data loading time 210.46325612068176 secs, data processing time 3.7257444858551025 secs\n",
      "\n",
      " epoch 16 Loss : 0.2903 Accuracy 0.88, time : 221.28221225738525 secs\n",
      "data loading time 210.1015341281891 secs, data processing time 3.8155622482299805 secs\n",
      "\n",
      " epoch 17 Loss : 0.2643 Accuracy 0.89, time : 221.15027022361755 secs\n",
      "data loading time 209.9272656440735 secs, data processing time 3.6178476810455322 secs\n",
      "\n",
      " epoch 18 Loss : 0.2747 Accuracy 0.88, time : 420.9866418838501 secs\n",
      "data loading time 409.1210501194 secs, data processing time 3.8295211791992188 secs\n",
      "\n",
      " epoch 19 Loss : 0.2695 Accuracy 0.89, time : 222.1067020893097 secs\n",
      "data loading time 210.99614906311035 secs, data processing time 3.7065114974975586 secs\n",
      "\n",
      " epoch 20 Loss : 0.2602 Accuracy 0.89, time : 222.5405833721161 secs\n",
      "data loading time 211.5500943660736 secs, data processing time 3.5972821712493896 secs\n",
      "\n",
      " epoch 21 Loss : 0.2607 Accuracy 0.89, time : 223.1434133052826 secs\n",
      "data loading time 211.88156127929688 secs, data processing time 3.831638813018799 secs\n",
      "\n",
      " epoch 22 Loss : 0.2652 Accuracy 0.89, time : 221.05274438858032 secs\n",
      "data loading time 209.93293929100037 secs, data processing time 3.782287120819092 secs\n",
      "\n",
      " epoch 23 Loss : 0.2551 Accuracy 0.89, time : 222.96004796028137 secs\n",
      "data loading time 211.66911673545837 secs, data processing time 3.857043504714966 secs\n",
      "\n",
      " epoch 24 Loss : 0.2663 Accuracy 0.88, time : 222.0036232471466 secs\n",
      "data loading time 210.79362034797668 secs, data processing time 3.894634246826172 secs\n",
      "\n",
      " epoch 25 Loss : 0.2550 Accuracy 0.90, time : 221.59054708480835 secs\n",
      "data loading time 210.22725319862366 secs, data processing time 3.8664395809173584 secs\n",
      "\n",
      " epoch 26 Loss : 0.2508 Accuracy 0.90, time : 238.9021327495575 secs\n",
      "data loading time 227.50646233558655 secs, data processing time 3.8080718517303467 secs\n",
      "\n",
      " epoch 27 Loss : 0.2562 Accuracy 0.89, time : 252.32670783996582 secs\n",
      "data loading time 240.80731582641602 secs, data processing time 3.956447124481201 secs\n",
      "\n",
      " epoch 28 Loss : 0.2568 Accuracy 0.89, time : 226.8189799785614 secs\n",
      "data loading time 215.56086897850037 secs, data processing time 3.7062771320343018 secs\n",
      "\n",
      " epoch 29 Loss : 0.2578 Accuracy 0.89, time : 223.77190852165222 secs\n",
      "data loading time 212.31273579597473 secs, data processing time 3.8072280883789062 secs\n"
     ]
    }
   ],
   "source": [
    "train_model(model_to_evaluate,\"res_net\",criterion=criterion, optimier=optimizer,\n",
    "            data_loader=train_dataloader, device=device, num_epochs=30)\n",
    "\n",
    "torch.save(model_to_evaluate.state_dict(),'resNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m res_net \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mresnet50()\n\u001b[0;32m      3\u001b[0m res_net\u001b[38;5;241m.\u001b[39mfc  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      4\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2048\u001b[39m,\u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[0;32m      7\u001b[0m         in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m----> 8\u001b[0m         out_features\u001b[38;5;241m=\u001b[39m\u001b[43mnum_classes\u001b[49m\n\u001b[0;32m      9\u001b[0m     ),\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m res_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresNet.h5\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "res_net = torchvision.models.resnet50()\n",
    "\n",
    "res_net.fc  = torch.nn.Sequential(\n",
    "    nn.Linear(2048,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(\n",
    "        in_features=128,\n",
    "        out_features=num_classes\n",
    "    ),\n",
    ")\n",
    "\n",
    "res_net.load_state_dict(torch.load('resNet.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += predictions.size(0)\n",
    "    model.train()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(20,20))\n",
    "  for n in range(len(image_batch)):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(label_batch[n])\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_batch, label_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m))\n\u001b[0;32m      2\u001b[0m show_batch(image_batch, label_batch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculate_accuracy(\u001b[43mtrain_dataloader\u001b[49m,\u001b[38;5;250m \u001b[39mres_net)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Accuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalculate_accuracy(test_dataloader,\u001b[38;5;250m \u001b[39mres_net)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy is {calculate_accuracy(train_dataloader, res_net)*100}\")\n",
    "\n",
    "print(f\"Testing Accuracy is {calculate_accuracy(test_dataloader, res_net)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
